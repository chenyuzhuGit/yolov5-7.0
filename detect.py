# Ultralytics YOLOv5 ğŸš€, AGPL-3.0 license
"""
æ³¨é‡Šæ¥æºï¼šhttps://blog.csdn.net/qq_51511878/article/details/130004796
Run YOLOv5 detection inference on images, videos, directories, globs, YouTube, webcam, streams, etc.

Usage - sources:
    $ python detect.py --weights yolov5s.pt --source 0                               # webcam
                                                     img.jpg                         # image
                                                     vid.mp4                         # video
                                                     screen                          # screenshot
                                                     path/                           # directory
                                                     list.txt                        # list of images
                                                     list.streams                    # list of streams
                                                     'path/*.jpg'                    # glob
                                                     'https://youtu.be/LNwODJXcvt4'  # YouTube
                                                     'rtsp://example.com/media.mp4'  # RTSP, RTMP, HTTP stream

Usage - formats:
    $ python detect.py --weights yolov5s.pt                 # PyTorch
                                 yolov5s.torchscript        # TorchScript
                                 yolov5s.onnx               # ONNX Runtime or OpenCV DNN with --dnn
                                 yolov5s_openvino_model     # OpenVINO
                                 yolov5s.engine             # TensorRT
                                 yolov5s.mlmodel            # CoreML (macOS-only)
                                 yolov5s_saved_model        # TensorFlow SavedModel
                                 yolov5s.pb                 # TensorFlow GraphDef
                                 yolov5s.tflite             # TensorFlow Lite
                                 yolov5s_edgetpu.tflite     # TensorFlow Edge TPU
                                 yolov5s_paddle_model       # PaddlePaddle

æµ‹è¯•å‘½ä»¤ï¼š
    1.é…ç½®å›¾ç‰‡è·¯å¾„
    2.è®¾ç½®æƒé‡æ–‡ä»¶ï¼Œä¸ºè®­ç»ƒå¥½çš„
    3.è®¾ç½®ç½®ä¿¡åº¦ä¸º0.4
python detect.py --source ./VOC/images/val/000001.jpg --weights
runs/exp0/weights/best.pt --conf 0.4

NMSç®—æ³•åŸç†
NMSç®—æ³•çš„æ ¸å¿ƒæ€æƒ³æ˜¯ä¿ç•™æ¯ä¸ªç›®æ ‡çš„æœ€é«˜ç½®ä¿¡åº¦çš„è¾¹ç•Œæ¡†ï¼ŒåŒæ—¶å»é™¤å…¶ä»–ä¸ä¹‹é«˜åº¦é‡å è¾¹ç•Œæ¡†ã€‚è¿™é‡Œçš„é‡å é€šå¸¸ç”¨äº¤å¹¶æ¯”IOUæ¥é‡åŒ–ã€‚
å…·ä½“æ­¥éª¤å¦‚ä¸‹ï¼š
ç®—æ³•åˆ†å‰²
æ’åº: é¦–å…ˆï¼Œæ ¹æ®æ¯ä¸ªè¾¹ç•Œæ¡†çš„ç½®ä¿¡åº¦ï¼ˆé€šå¸¸æ˜¯åˆ†ç±»æ¦‚ç‡ä¸å®šä½å‡†ç¡®åº¦çš„ç»¼åˆæŒ‡æ ‡ï¼‰è¿›è¡Œé™åºæ’åˆ—ã€‚ç½®ä¿¡åº¦æœ€é«˜çš„è¾¹ç•Œæ¡†è¢«è®¤ä¸ºæ˜¯æœ€æœ‰å¯èƒ½æ­£ç¡®æ£€æµ‹åˆ°ç›®æ ‡çš„ã€‚
é€‰æ‹©: ä»æ’åºåçš„åˆ—è¡¨ä¸­é€‰æ‹©ç½®ä¿¡åº¦æœ€é«˜çš„è¾¹ç•Œæ¡†ï¼Œæ ‡è®°ä¸ºå·²é€‰ï¼Œå¹¶å°†å…¶æ·»åŠ åˆ°æœ€ç»ˆçš„æ£€æµ‹ç»“æœåˆ—è¡¨ä¸­ã€‚
è®¡ç®—IOU: å¯¹äºå‰©ä½™çš„æ¯ä¸ªè¾¹ç•Œæ¡†ï¼Œè®¡ç®—å®ƒä¸å·²é€‰è¾¹ç•Œæ¡†çš„IOUã€‚
æ¯”è¾ƒä¸å‰”é™¤: å¦‚æœæŸä¸ªè¾¹ç•Œæ¡†ä¸å·²é€‰æ¡†çš„IOUè¶…è¿‡äº†é¢„è®¾çš„é˜ˆå€¼ï¼ˆä¾‹å¦‚0.5æˆ–0.7ï¼‰ï¼Œåˆ™è®¤ä¸ºè¿™ä¸¤ä¸ªæ¡†è¡¨ç¤ºçš„æ˜¯åŒä¸€ä¸ªç›®æ ‡ï¼Œäºæ˜¯æ ¹æ®ç½®ä¿¡åº¦è¾ƒä½çš„åŸåˆ™ï¼Œå‰”é™¤è¿™ä¸ªä½ç½®ä¿¡åº¦çš„è¾¹ç•Œæ¡†ã€‚
é‡å¤æ­¥éª¤2-4: ç»§ç»­é€‰æ‹©å‰©ä½™è¾¹ç•Œæ¡†ä¸­ç½®ä¿¡åº¦æœ€é«˜çš„ï¼Œé‡å¤è®¡ç®—IOUå’Œå‰”é™¤è¿‡ç¨‹ï¼Œç›´åˆ°æ‰€æœ‰è¾¹ç•Œæ¡†éƒ½è¢«æ£€æŸ¥è¿‡ã€‚
ç»“æŸ: æœ€ç»ˆï¼Œå‰©ä¸‹çš„è¾¹ç•Œæ¡†é›†åˆå³ä¸ºç»è¿‡NMSå¤„ç†åçš„æ£€æµ‹ç»“æœï¼Œæ¯ä¸ªç›®æ ‡å¯¹åº”ä¸€ä¸ªæœ€ä¼˜çš„è¾¹ç•Œæ¡†ã€‚

åŸæ–‡é“¾æ¥ï¼šhttps://blog.csdn.net/m0_74055982/article/details/138647169
"""

'''====================1.å¯¼å…¥å®‰è£…å¥½çš„pythonåº“======================='''

import argparse  # è§£æå‘½ä»¤è¡Œå‚æ•°çš„åº“
import csv
import os  # ä¸æ“ä½œç³»ç»Ÿè¿›è¡Œäº¤äº’çš„æ–‡ä»¶åº“ åŒ…å«æ–‡ä»¶è·¯å¾„æ“ä½œä¸è§£æ
import platform
import sys  # sysæ¨¡å—åŒ…å«äº†ä¸pythonè§£é‡Šå™¨å’Œå®ƒçš„ç¯å¢ƒæœ‰å…³çš„å‡½æ•°ã€‚
from pathlib import Path  # Pathèƒ½å¤Ÿæ›´åŠ æ–¹ä¾¿å¾—å¯¹å­—ç¬¦ä¸²è·¯å¾„è¿›è¡Œå¤„ç†

# pytorch æ·±åº¦å­¦ä¹ åº“
import torch

'''=====================2.è·å–å½“å‰æ–‡ä»¶çš„ç»å¯¹è·¯å¾„=============================='''
# __file__æŒ‡çš„æ˜¯å½“å‰æ–‡ä»¶(å³detect.py),FILEæœ€ç»ˆä¿å­˜ç€å½“å‰æ–‡ä»¶çš„ç»å¯¹è·¯å¾„,æ¯”å¦‚D://yolov5/detect.py
FILE = Path(__file__).resolve()
# YOLOv5 root directory  ROOTä¿å­˜ç€å½“å‰é¡¹ç›®çš„çˆ¶ç›®å½•,æ¯”å¦‚ D://yolov5
ROOT = FILE.parents[0]
# sys.pathå³å½“å‰pythonç¯å¢ƒå¯ä»¥è¿è¡Œçš„è·¯å¾„,å‡å¦‚å½“å‰é¡¹ç›®ä¸åœ¨è¯¥è·¯å¾„ä¸­,å°±æ— æ³•è¿è¡Œå…¶ä¸­çš„æ¨¡å—,æ‰€ä»¥å°±éœ€è¦åŠ è½½è·¯å¾„
if str(ROOT) not in sys.path:
    # add ROOT to PATH  æŠŠROOTæ·»åŠ åˆ°è¿è¡Œè·¯å¾„ä¸Š
    sys.path.append(str(ROOT))
# relative ROOTè®¾ç½®ä¸ºç›¸å¯¹è·¯å¾„
ROOT = Path(os.path.relpath(ROOT, Path.cwd()))
# è¿™ä¸ªæ–‡ä»¶å®šä¹‰äº†Annotatorç±»ï¼Œå¯ä»¥åœ¨å›¾åƒä¸Šç»˜åˆ¶çŸ©å½¢æ¡†å’Œæ ‡æ³¨ä¿¡æ¯
from ultralytics.utils.plotting import Annotator, colors, save_one_box

'''=====================3..åŠ è½½è‡ªå®šä¹‰æ¨¡å—============================='''
# models.commonè¿™ä¸ªæ–‡ä»¶å®šä¹‰äº†ä¸€äº›é€šç”¨çš„å‡½æ•°å’Œç±»ï¼Œæ¯”å¦‚å›¾åƒçš„å¤„ç†ã€éæå¤§å€¼æŠ‘åˆ¶ç­‰ç­‰ã€‚
from models.common import DetectMultiBackend
# utils.dataloadersè¿™ä¸ªæ–‡ä»¶å®šä¹‰äº†ä¸¤ä¸ªç±»ï¼ŒLoadImageså’ŒLoadStreamsï¼Œ
# å®ƒä»¬å¯ä»¥åŠ è½½å›¾åƒæˆ–è§†é¢‘å¸§ï¼Œå¹¶å¯¹å®ƒä»¬è¿›è¡Œä¸€äº›é¢„å¤„ç†ï¼Œä»¥ä¾¿è¿›è¡Œç‰©ä½“æ£€æµ‹æˆ–è¯†åˆ«ã€‚
from utils.dataloaders import IMG_FORMATS, VID_FORMATS, LoadImages, LoadScreenshots, LoadStreams
# è¿™ä¸ªæ–‡ä»¶å®šä¹‰äº†ä¸€äº›å¸¸ç”¨çš„å·¥å…·å‡½æ•°ï¼Œæ¯”å¦‚æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ã€æ£€æŸ¥å›¾åƒå¤§å°æ˜¯å¦ç¬¦åˆè¦æ±‚ã€æ‰“å°å‘½ä»¤è¡Œå‚æ•°ç­‰ç­‰
from utils.general import (
    LOGGER,
    Profile,
    check_file,
    check_img_size,
    check_imshow,
    check_requirements,
    colorstr,
    cv2,
    increment_path,
    non_max_suppression,
    print_args,
    scale_boxes,
    strip_optimizer,
    xyxy2xywh,
)
# utils.torch_utilsè¿™ä¸ªæ–‡ä»¶å®šä¹‰äº†ä¸€äº›ä¸PyTorchæœ‰å…³çš„å·¥å…·å‡½æ•°ï¼Œæ¯”å¦‚é€‰æ‹©è®¾å¤‡ã€åŒæ­¥æ—¶é—´ç­‰ç­‰ã€‚
from utils.torch_utils import select_device, smart_inference_mode


'''===================1.è½½å…¥å‚æ•°======================='''
# smart_inference_modeï¼šç”¨äºè‡ªåŠ¨åˆ‡æ¢æ¨¡å‹çš„æ¨ç†æ¨¡å¼ï¼Œå¦‚æœæ˜¯FP16æ¨¡å‹ï¼Œåˆ™è‡ªåŠ¨åˆ‡æ¢ä¸ºFP16æ¨ç†æ¨¡å¼
#    å¦åˆ™åˆ‡æ¢ä¸ºFP32æ¨ç†æ¨¡å¼ï¼Œè¿™æ ·å¯ä»¥é¿å…æ¨¡å‹æ¨ç†æ—¶å‡ºç°ç±»å‹ä¸åŒ¹é…çš„é”™è¯¯
@smart_inference_mode()
def run(
    weights=ROOT / "yolov5s.pt",  # model path or triton URL
    source=ROOT / "data/images",  # file/dir/URL/glob/screen/0(webcam)
    data=ROOT / "data/coco128.yaml",  # dataset.yaml path
    imgsz=(640, 640),  # inference size (height, width)
    conf_thres=0.25,  # confidence threshold
    iou_thres=0.45,  # NMS IOU threshold
    max_det=1000,  # maximum detections per image
    device="",  # cuda device, i.e. 0 or 0,1,2,3 or cpu
    view_img=False,  # show results
    save_txt=False,  # save results to *.txt
    save_csv=False,  # save results in CSV format
    save_conf=False,  # save confidences in --save-txt labels
    save_crop=False,  # save cropped prediction boxes
    nosave=False,  # do not save images/videos
    classes=None,  # filter by class: --class 0, or --class 0 2 3
    agnostic_nms=False,  # class-agnostic NMS
    augment=False,  # augmented inference
    visualize=False,  # visualize features
    update=False,  # update all models
    project=ROOT / "runs/detect",  # save results to project/name
    name="exp",  # save results to project/name
    exist_ok=False,  # existing project/name ok, do not increment
    line_thickness=3,  # bounding box thickness (pixels)
    hide_labels=False,  # hide labels
    hide_conf=False,  # hide confidences
    half=False,  # use FP16 half-precision inference
    dnn=False,  # use OpenCV DNN for ONNX inference
    vid_stride=1,  # video frame-rate stride
):
    """
    ä¸»å‡½æ•°
    :return:
    """
    # ---------------------åˆå§‹åŒ–å‚æ•°---------------------------------------------------------------------------
    # å°†sourceè½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œ sourceä¸ºè¾“å…¥çš„å›¾ç‰‡ï¼Œè§†é¢‘ï¼Œæ‘„åƒå¤´ç­‰
    source = str(source)

    # åˆ¤æ–­æ˜¯å¦ä¿å­˜å›¾ç‰‡ï¼Œå¦‚æœnosaveä¸ºFalseï¼Œä¸”sourceä¸æ˜¯txtæ–‡ä»¶ï¼Œåˆ™ä¿å­˜å›¾ç‰‡
    save_img = not nosave and not source.endswith(".txt")  # save inference images

    # åˆ¤æ–­sourceæ˜¯ä¸æ˜¯è§†é¢‘/å›¾åƒæ–‡ä»¶è·¯å¾„
    # Path()æå–æ–‡ä»¶åã€‚suffixï¼šæœ€åä¸€ä¸ªç»„ä»¶çš„æ–‡ä»¶æ‰©å±•åã€‚è‹¥sourceæ˜¯"D://YOLOv5/data/1.jpg"ï¼Œ åˆ™Path(source).suffixæ˜¯".jpg"ï¼Œ Path(source).suffix[1:]æ˜¯"jpg"
    # è€ŒIMG_FORMATS å’Œ VID_FORMATSä¸¤ä¸ªå˜é‡ä¿å­˜çš„æ˜¯æ‰€æœ‰çš„è§†é¢‘å’Œå›¾ç‰‡çš„æ ¼å¼åç¼€ã€‚
    is_file = Path(source).suffix[1:] in (IMG_FORMATS + VID_FORMATS)

    # åˆ¤æ–­sourceæ˜¯å¦æ˜¯urlï¼Œå¦‚æœæ˜¯ï¼Œåˆ™is_urlä¸ºTrue.lower()å°†å­—ç¬¦ä¸²è½¬æ¢ä¸ºå°å†™,startswith()åˆ¤æ–­å­—ç¬¦ä¸²æ˜¯å¦ä»¥æŒ‡å®šçš„å­—ç¬¦ä¸²å¼€å¤´
    is_url = source.lower().startswith(("rtsp://", "rtmp://", "http://", "https://"))

    # åˆ¤æ–­sourceæ˜¯å¦æ˜¯æ•°å­—ï¼Œsource.endswith('.streams')åˆ¤æ–­sourceæ˜¯å¦ä»¥.streamsç»“å°¾ï¼Œ
    # (is_url and not is_file)åˆ¤æ–­sourceæ˜¯å¦æ˜¯urlï¼Œä¸”ä¸æ˜¯æ–‡ä»¶ï¼Œä¸Šè¿°ä¸‰ä¸ªæ¡ä»¶æœ‰ä¸€ä¸ªä¸ºTrueï¼Œåˆ™webcamä¸ºTrueã€‚
    webcam = source.isnumeric() or source.endswith(".streams") or (is_url and not is_file)

    # åˆ¤æ–­sourceæ˜¯å¦æ˜¯æˆªå›¾ï¼Œå¦‚æœæ˜¯ï¼Œåˆ™screenshotä¸ºTrue
    screenshot = source.lower().startswith("screen")
    if is_url and is_file:
        # ç¡®ä¿è¾“å…¥æºä¸ºæœ¬åœ°æ–‡ä»¶ï¼Œå¦‚æœæ˜¯urlï¼Œåˆ™ä¸‹è½½åˆ°æœ¬åœ°ï¼Œcheck_file()å‡½æ•°ç”¨äºä¸‹è½½urlæ–‡ä»¶
        source = check_file(source)  # download

    # Directories
    '''========================3.ä¿å­˜ç»“æœ======================'''
    # åˆ›å»ºä¿å­˜ç»“æœçš„æ–‡ä»¶å¤¹
    # å¢åŠ æ–‡ä»¶æˆ–ç›®å½•è·¯å¾„ï¼Œå³è¿è¡Œ/expâ€”â€”>è¿è¡Œ/exp{sep}2ï¼Œè¿è¡Œ/exp{sep}3ï¼Œâ€¦ç­‰ã€‚exist_okä¸ºTrueæ—¶ï¼Œå¦‚æœæ–‡ä»¶å¤¹å·²å­˜åœ¨ï¼Œåˆ™ä¸ä¼šæŠ¥é”™
    save_dir = increment_path(Path(project) / name, exist_ok=exist_ok)  # increment run
    # åˆ›å»ºæ–‡ä»¶å¤¹ï¼Œå¦‚æœsave_txtä¸ºTrueï¼Œåˆ™åˆ›å»ºlabelsæ–‡ä»¶å¤¹ï¼Œå¦åˆ™åˆ›å»ºsave_diræ–‡ä»¶å¤¹
    (save_dir / "labels" if save_txt else save_dir).mkdir(parents=True, exist_ok=True)  # make dir

    # Load model
    '''=======================4.åŠ è½½æ¨¡å‹=========================='''
    # é€‰æ‹©è®¾å¤‡ï¼Œå¦‚æœdeviceä¸ºç©ºï¼Œåˆ™è‡ªåŠ¨é€‰æ‹©è®¾å¤‡
    device = select_device(device)
    # åŠ è½½æ¨¡å‹ï¼ŒDetectMultiBackend()å‡½æ•°ç”¨äºåŠ è½½æ¨¡å‹ï¼Œweightsä¸ºæ¨¡å‹è·¯å¾„ï¼Œdeviceä¸ºè®¾å¤‡ï¼Œdnnä¸ºæ˜¯å¦ä½¿ç”¨opencv dnnï¼Œdataä¸ºæ•°æ®é›†ï¼Œfp16ä¸ºæ˜¯å¦ä½¿ç”¨fp16æ¨ç†
    model = DetectMultiBackend(weights, device=device, dnn=dnn, data=data, fp16=half)
    '''
        strideï¼šæ¨ç†æ—¶æ‰€ç”¨åˆ°çš„æ­¥é•¿ï¼Œé»˜è®¤ä¸º32ï¼Œ å¤§æ­¥é•¿é€‚åˆäºå¤§ç›®æ ‡ï¼Œå°æ­¥é•¿é€‚åˆäºå°ç›®æ ‡
        namesï¼šä¿å­˜æ¨ç†ç»“æœåçš„åˆ—è¡¨ï¼Œæ¯”å¦‚é»˜è®¤æ¨¡å‹çš„å€¼æ˜¯['person', 'bicycle', 'car', ...] 
        pt: åŠ è½½çš„æ˜¯å¦æ˜¯pytorchæ¨¡å‹ï¼ˆä¹Ÿå°±æ˜¯ptæ ¼å¼çš„æ–‡ä»¶ï¼‰
        jitï¼šå½“æŸæ®µä»£ç å³å°†ç¬¬ä¸€æ¬¡è¢«æ‰§è¡Œæ—¶è¿›è¡Œç¼–è¯‘ï¼Œå› è€Œå«â€œå³æ—¶ç¼–è¯‘â€
        onnxï¼šåˆ©ç”¨Pytorchæˆ‘ä»¬å¯ä»¥å°†model.ptè½¬åŒ–ä¸ºmodel.onnxæ ¼å¼çš„æƒé‡ï¼Œåœ¨è¿™é‡Œonnxå……å½“ä¸€ä¸ªåç¼€åç§°ï¼Œ
              model.onnxå°±ä»£è¡¨ONNXæ ¼å¼çš„æƒé‡æ–‡ä»¶ï¼Œè¿™ä¸ªæƒé‡æ–‡ä»¶ä¸ä»…åŒ…å«äº†æƒé‡å€¼ï¼Œä¹ŸåŒ…å«äº†ç¥ç»ç½‘ç»œçš„ç½‘ç»œæµåŠ¨ä¿¡æ¯ä»¥åŠæ¯ä¸€å±‚ç½‘ç»œçš„è¾“å…¥è¾“å‡ºä¿¡æ¯å’Œä¸€äº›å…¶ä»–çš„è¾…åŠ©ä¿¡æ¯ã€‚
    '''
    # ç¡®ä¿è¾“å…¥å›¾ç‰‡çš„å°ºå¯¸imgszèƒ½æ•´é™¤stride=32 å¦‚æœä¸èƒ½åˆ™è°ƒæ•´ä¸ºèƒ½è¢«æ•´é™¤å¹¶è¿”å›
    stride, names, pt = model.stride, model.names, model.pt
    # éªŒè¯å›¾åƒå¤§å°æ˜¯æ¯ä¸ªç»´åº¦çš„stride=32çš„å€æ•°,å¦‚æœä¸èƒ½åˆ™è°ƒæ•´ä¸ºèƒ½è¢«æ•´é™¤å¹¶è¿”å›
    imgsz = check_img_size(imgsz, s=stride)  # check image size

    '''=======================5.åŠ è½½æ•°æ®========================'''
    # Dataloader
    # é€šè¿‡ä¸åŒçš„è¾“å…¥æºæ¥è®¾ç½®ä¸åŒçš„æ•°æ®åŠ è½½æ–¹å¼
    # åˆå§‹åŒ–batch_size=1
    bs = 1  # batch_size

    # å¦‚æœsourceæ˜¯æ‘„åƒå¤´ï¼Œåˆ™åˆ›å»ºLoadStreams()å¯¹è±¡
    if webcam:
        # æ˜¯å¦æ˜¾ç¤ºå›¾ç‰‡ï¼Œå¦‚æœview_imgä¸ºTrueï¼Œåˆ™æ˜¾ç¤ºå›¾ç‰‡
        view_img = check_imshow(warn=True)
        # åˆ›å»ºLoadStreams()å¯¹è±¡ï¼Œsourceä¸ºè¾“å…¥æºï¼Œimg_sizeä¸ºå›¾åƒå¤§å°ï¼Œstrideä¸ºæ¨¡å‹çš„strideï¼Œautoä¸ºæ˜¯å¦è‡ªåŠ¨é€‰æ‹©è®¾å¤‡ï¼Œvid_strideä¸ºè§†é¢‘å¸§ç‡
        dataset = LoadStreams(source, img_size=imgsz, stride=stride, auto=pt, vid_stride=vid_stride)
        # batch_sizeä¸ºæ•°æ®é›†çš„é•¿åº¦
        bs = len(dataset)
    elif screenshot:
        # å¦‚æœsourceæ˜¯æˆªå›¾ï¼Œåˆ™åˆ›å»ºLoadScreenshots()å¯¹è±¡
        # åˆ›å»ºLoadScreenshots()å¯¹è±¡ï¼Œsourceä¸ºè¾“å…¥æºï¼Œimg_sizeä¸ºå›¾åƒå¤§å°ï¼Œstrideä¸ºæ¨¡å‹çš„strideï¼Œautoä¸ºæ˜¯å¦è‡ªåŠ¨é€‰æ‹©è®¾å¤‡
        dataset = LoadScreenshots(source, img_size=imgsz, stride=stride, auto=pt)
    else:
        # åˆ›å»ºLoadImages()å¯¹è±¡ï¼Œç›´æ¥åŠ è½½å›¾ç‰‡ï¼Œsourceä¸ºè¾“å…¥æºï¼Œimg_sizeä¸ºå›¾åƒå¤§å°ï¼Œstrideä¸ºæ¨¡å‹çš„strideï¼Œautoä¸ºæ˜¯å¦è‡ªåŠ¨é€‰æ‹©è®¾å¤‡ï¼Œvid_strideä¸ºè§†é¢‘å¸§ç‡
        dataset = LoadImages(source, img_size=imgsz, stride=stride, auto=pt, vid_stride=vid_stride)

    # åˆå§‹åŒ–vid_pathå’Œvid_writerï¼Œvid_pathä¸ºè§†é¢‘è·¯å¾„ï¼Œvid_writerä¸ºè§†é¢‘å†™å…¥å¯¹è±¡
    vid_path, vid_writer = [None] * bs, [None] * bs

    # ---------------------å¼€å§‹æ¨ç†---------------------------------------------------------------------------
    # Run inferenceï¼šè¿è¡Œæ¨ç†
    # warmupï¼Œé¢„çƒ­ï¼Œç”¨äºæå‰åŠ è½½æ¨¡å‹ï¼ŒåŠ å¿«æ¨ç†é€Ÿåº¦ï¼Œimgszä¸ºå›¾åƒå¤§å°ï¼Œå¦‚æœptä¸ºTrueæˆ–è€…model.tritonä¸ºTrueï¼Œåˆ™bs&#61;1ï¼Œå¦åˆ™bsä¸ºæ•°æ®é›†çš„é•¿åº¦ã€‚3ä¸ºé€šé“æ•°ï¼Œ*imgszä¸ºå›¾åƒå¤§å°ï¼Œå³(1,3,640,640)
    model.warmup(imgsz=(1 if pt or model.triton else bs, 3, *imgsz))  # warmup
    # åˆå§‹åŒ–seenï¼Œwindowsï¼Œdtï¼Œseenä¸ºå·²æ£€æµ‹çš„å›¾ç‰‡æ•°é‡ï¼Œwindowsä¸ºç©ºåˆ—è¡¨ï¼Œdtä¸ºæ—¶é—´ç»Ÿè®¡å¯¹è±¡
    seen, windows, dt = 0, [], (Profile(device=device), Profile(device=device), Profile(device=device))
    # éå†æ•°æ®é›†ï¼Œpathä¸ºå›¾ç‰‡è·¯å¾„ï¼Œimä¸ºå›¾ç‰‡ï¼Œim0sä¸ºåŸå§‹å›¾ç‰‡ï¼Œvid_capä¸ºè§†é¢‘è¯»å–å¯¹è±¡ï¼Œsä¸ºè§†é¢‘å¸§ç‡
    for path, im, im0s, vid_cap, s in dataset:
        '''
         åœ¨datasetä¸­ï¼Œæ¯æ¬¡è¿­ä»£çš„è¿”å›å€¼æ˜¯self.sources, img, img0, None, ''
          pathï¼šæ–‡ä»¶è·¯å¾„ï¼ˆå³sourceï¼‰
          im: resizeåçš„å›¾ç‰‡ï¼ˆç»è¿‡äº†æ”¾ç¼©æ“ä½œï¼‰
          im0s: åŸå§‹å›¾ç‰‡
          vid_cap=none
          sï¼š å›¾ç‰‡çš„åŸºæœ¬ä¿¡æ¯ï¼Œæ¯”å¦‚è·¯å¾„ï¼Œå¤§å°
        '''
        # å¼€å§‹è®¡æ—¶,è¯»å–å›¾ç‰‡
        with dt[0]:
            # # å°†å›¾ç‰‡æ”¾åˆ°æŒ‡å®šè®¾å¤‡(å¦‚GPU)ä¸Šè¯†åˆ«ã€‚#torch.size=[3,640,480]
            # å°†å›¾ç‰‡è½¬æ¢ä¸ºtensorï¼Œå¹¶æ”¾åˆ°æ¨¡å‹çš„è®¾å¤‡ä¸Šï¼Œpytorchæ¨¡å‹çš„è¾“å…¥å¿…é¡»æ˜¯tensor
            im = torch.from_numpy(im).to(model.device)
            # uint8 to fp16/32
            # å¦‚æœæ¨¡å‹ä½¿ç”¨fp16æ¨ç†ï¼Œåˆ™å°†å›¾ç‰‡è½¬æ¢ä¸ºfp16ï¼Œå¦åˆ™è½¬æ¢ä¸ºfp32
            im = im.half() if model.fp16 else im.float()  # uint8 to fp16/32
            # å°†å›¾ç‰‡å½’ä¸€åŒ–ï¼Œå°†å›¾ç‰‡åƒç´ å€¼ä»0-255è½¬æ¢ä¸º0-1
            im /= 255  # 0 - 255 to 0.0 - 1.0
            # å¦‚æœå›¾ç‰‡çš„ç»´åº¦ä¸º3ï¼Œåˆ™æ·»åŠ batchç»´åº¦
            if len(im.shape) == 3:
                # åœ¨å‰é¢æ·»åŠ batchç»´åº¦ï¼Œå³å°†å›¾ç‰‡çš„ç»´åº¦ä»3ç»´è½¬æ¢ä¸º4ç»´ï¼Œå³(3,640,640)è½¬æ¢ä¸º(1,3,640,640)ï¼Œpytorchæ¨¡å‹çš„è¾“å…¥å¿…é¡»æ˜¯4ç»´çš„
                im = im[None]  # expand for batch dim

            # æ£€æŸ¥æ¨¡å‹çš„xmlå±æ€§æ˜¯å¦ä¸ºçœŸï¼Œä¸”ç¬¬ä¸€ä¸ªç»´åº¦æ˜¯å¦å¤§äº1
            if model.xml and im.shape[0] > 1:
                # å¦‚æœæ¡ä»¶æ»¡è¶³ï¼Œä¼šä½¿ç”¨torch.chunkå‡½æ•°å°†imæŒ‰è¡Œåˆ†å‰²æˆå¤šä¸ªå¼ é‡ï¼Œå¹¶å°†è¿™äº›å¼ é‡å­˜å‚¨åœ¨åä¸ºimsçš„åˆ—è¡¨ä¸­
                ims = torch.chunk(im, im.shape[0], 0)

        # Inference æ¨ç†
        # å¼€å§‹è®¡æ—¶,æ¨ç†æ—¶é—´
        with dt[1]:
            # å¯è§†åŒ–æ–‡ä»¶è·¯å¾„ã€‚å¦‚æœä¸ºTrueåˆ™ä¿ç•™æ¨ç†è¿‡ç¨‹ä¸­çš„ç‰¹å¾å›¾ï¼Œä¿å­˜åœ¨runsæ–‡ä»¶å¤¹ä¸­
            # å¦‚æœvisualizeä¸ºTrueï¼Œåˆ™åˆ›å»ºvisualizeæ–‡ä»¶å¤¹ï¼Œå¦åˆ™ä¸ºFalse
            visualize = increment_path(save_dir / Path(path).stem, mkdir=True) if visualize else False
            # æ£€æŸ¥æ¨¡å‹çš„xmlå±æ€§æ˜¯å¦ä¸ºçœŸï¼Œä¸”ç¬¬ä¸€ä¸ªç»´åº¦æ˜¯å¦å¤§äº1
            if model.xml and im.shape[0] > 1:
                pred = None
                # å¯¹åˆ†å—åçš„å›¾åƒæ•°æ®è¿›è¡Œæ¨ç†ï¼Œå°†æ¯ä¸ªå›¾åƒçš„é¢„æµ‹ç»“æœå­˜å‚¨åœ¨predä¸­ã€‚
                for image in ims:
                    if pred is None:
                        pred = model(image, augment=augment, visualize=visualize).unsqueeze(0)
                    else:
                        pred = torch.cat((pred, model(image, augment=augment, visualize=visualize).unsqueeze(0)), dim=0)
                pred = [pred, None]
            else:
                # å¦åˆ™ï¼Œç›´æ¥å¯¹å•ä¸ªå›¾åƒæ•°æ®è¿›è¡Œæ¨ç†ï¼Œå°†é¢„æµ‹ç»“æœå­˜å‚¨åœ¨predä¸­ã€‚
                # æ¨ç†ï¼Œmodel()å‡½æ•°ç”¨äºæ¨ç†ï¼Œimä¸ºè¾“å…¥å›¾ç‰‡ï¼Œaugmentä¸ºæ˜¯å¦ä½¿ç”¨æ•°æ®å¢å¼ºï¼Œvisualizeä¸ºæ˜¯å¦å¯è§†åŒ–,è¾“å‡ºpredä¸ºä¸€ä¸ªåˆ—è¡¨ï¼Œ
                # å½¢çŠ¶ä¸ºï¼ˆn,6ï¼‰,nä»£è¡¨é¢„æµ‹æ¡†çš„æ•°é‡ï¼Œ6ä»£è¡¨é¢„æµ‹æ¡†çš„åæ ‡å’Œç½®ä¿¡åº¦ï¼Œç±»åˆ«
                pred = model(im, augment=augment, visualize=visualize)
        # NMS
        # NMSï¼Œéæå¤§å€¼æŠ‘åˆ¶ï¼Œç”¨äºå»é™¤é‡å¤çš„é¢„æµ‹æ¡†
        with dt[2]:
            # NMSï¼Œnon_max_suppression()å‡½æ•°ç”¨äºNMSï¼Œpredä¸ºè¾“å…¥çš„é¢„æµ‹æ¡†ï¼Œconf_thresä¸ºç½®ä¿¡åº¦é˜ˆå€¼ï¼Œiou_thresä¸ºioué˜ˆå€¼ï¼Œclassesä¸ºç±»åˆ«ï¼Œagnostic_nmsä¸ºæ˜¯å¦ä½¿ç”¨ç±»åˆ«æ— å…³çš„NMSï¼Œmax_detä¸ºæœ€å¤§æ£€æµ‹æ¡†æ•°é‡:é»˜è®¤1000ï¼Œ
            pred = non_max_suppression(pred, conf_thres, iou_thres, classes, agnostic_nms, max_det=max_det)

        # Second-stage classifier (optional)
        # pred = utils.general.apply_classifier(pred, classifier_model, im, im0s)

        # Define the path for the CSV file
        # å®šä¹‰CSVæ–‡ä»¶çš„è·¯å¾„
        csv_path = save_dir / "predictions.csv"

        # Create or append to the CSV file
        # åˆ›å»ºæˆ–é™„åŠ åˆ°CSVæ–‡ä»¶
        def write_to_csv(image_name, prediction, confidence):
            """Writes prediction data for an image to a CSV file, appending if the file exists."""
            data = {"Image Name": image_name, "Prediction": prediction, "Confidence": confidence}
            with open(csv_path, mode="a", newline="") as f:
                writer = csv.DictWriter(f, fieldnames=data.keys())
                if not csv_path.is_file():
                    writer.writeheader()
                writer.writerow(data)

        # Process predictions
        # å¤„ç†é¢„æµ‹ç»“æœ
        # éå†æ¯å¼ å›¾ç‰‡,enumerate()å‡½æ•°å°†predè½¬æ¢ä¸ºç´¢å¼•å’Œå€¼çš„å½¢å¼ï¼Œiä¸ºç´¢å¼•ï¼Œdetä¸ºå¯¹åº”çš„å…ƒç´ ï¼Œå³æ¯ä¸ªç‰©ä½“çš„é¢„æµ‹æ¡†
        # æŠŠæ‰€æœ‰çš„æ£€æµ‹æ¡†ç”»åˆ°åŸå›¾ä¸­
        for i, det in enumerate(pred):  # per image
            '''
                iï¼šæ¯ä¸ªbatchçš„ä¿¡æ¯
                det:è¡¨ç¤º5ä¸ªæ£€æµ‹æ¡†çš„ä¿¡æ¯
            '''
            # æ¯æ¬¡è¿­ä»£å¤„ç†ä¸€å¼ å›¾ç‰‡
            # æ£€æµ‹çš„å›¾ç‰‡æ•°é‡åŠ 1
            # seenæ˜¯ä¸€ä¸ªè®¡æ•°çš„åŠŸèƒ½
            seen += 1

            # å¦‚æœæ˜¯æ‘„åƒå¤´ï¼Œåˆ™è·å–è§†é¢‘å¸§ç‡
            if webcam:  # batch_size >= 1
                # path[i]ä¸ºè·¯å¾„åˆ—è¡¨ï¼Œims[i].copy()ä¸ºå°†è¾“å…¥å›¾åƒçš„å‰¯æœ¬å­˜å‚¨åœ¨im0å˜é‡ä¸­ï¼Œdataset.countä¸ºå½“å‰è¾“å…¥å›¾åƒçš„å¸§æ•°
                p, im0, frame = path[i], im0s[i].copy(), dataset.count
                # åœ¨æ‰“å°è¾“å‡ºä¸­æ·»åŠ å½“å‰å¤„ç†çš„å›¾åƒç´¢å¼•å·iï¼Œæ–¹ä¾¿è°ƒè¯•å’ŒæŸ¥çœ‹ç»“æœã€‚åœ¨æ­¤å¤„ï¼Œå¦‚æœæ˜¯æ‘„åƒå¤´æ¨¡å¼ï¼Œiè¡¨ç¤ºå½“å‰æ‰¹æ¬¡ä¸­ç¬¬iå¼ å›¾åƒ;å¦åˆ™ï¼Œiå§‹ç»ˆä¸º0ï¼Œå› ä¸ºå¤„ç†çš„åªæœ‰ä¸€å¼ å›¾åƒã€‚
                s += f"{i}: "
            else:
                # å¦‚æœä¸æ˜¯æ‘„åƒå¤´ï¼Œframeä¸º0
                p, im0, frame = path, im0s.copy(), getattr(dataset, "frame", 0)
                '''
                    å¤§éƒ¨åˆ†æˆ‘ä»¬ä¸€èˆ¬éƒ½æ˜¯ä»LoadImagesæµè¯»å–æœ¬éƒ½æ–‡ä»¶ä¸­çš„ç…§ç‰‡æˆ–è€…è§†é¢‘ æ‰€ä»¥batch_size=1
                       p: å½“å‰å›¾ç‰‡/è§†é¢‘çš„ç»å¯¹è·¯å¾„ å¦‚ F:\yolo_v5\yolov5-U\data\images\bus.jpg
                       s: è¾“å‡ºä¿¡æ¯ åˆå§‹ä¸º ''
                       im0: åŸå§‹å›¾ç‰‡ letterbox + pad ä¹‹å‰çš„å›¾ç‰‡
                       frame: è§†é¢‘æµ,æ­¤æ¬¡å–çš„æ˜¯ç¬¬å‡ å¼ å›¾ç‰‡
                '''

            # å°†è·¯å¾„è½¬æ¢ä¸ºPathå¯¹è±¡:å›¾ç‰‡/è§†é¢‘çš„ä¿å­˜è·¯å¾„save_path å¦‚ runs\\detect\\exp8\\fire.jpg
            p = Path(p)  # to Path
            # im.jpgï¼Œä¿å­˜å›¾ç‰‡çš„è·¯å¾„ï¼Œsave_dirä¸ºä¿å­˜å›¾ç‰‡çš„æ–‡ä»¶å¤¹ï¼Œp.nameä¸ºå›¾ç‰‡åç§°
            save_path = str(save_dir / p.name)  # im.jpg
            # im.txtï¼Œä¿å­˜é¢„æµ‹æ¡†çš„è·¯å¾„ï¼Œsave_dirä¸ºä¿å­˜å›¾ç‰‡çš„æ–‡ä»¶å¤¹ï¼Œp.stemä¸ºå›¾ç‰‡åç§°ï¼Œdataset.modeä¸ºæ•°æ®é›†çš„æ¨¡å¼ï¼Œå¦‚æœæ˜¯imageï¼Œåˆ™ä¸ºå›¾ç‰‡ï¼Œå¦åˆ™ä¸ºè§†é¢‘
            # è®¾ç½®ä¿å­˜æ¡†åæ ‡çš„txtæ–‡ä»¶è·¯å¾„ï¼Œæ¯å¼ å›¾ç‰‡å¯¹åº”ä¸€ä¸ªæ¡†åæ ‡ä¿¡æ¯
            txt_path = str(save_dir / "labels" / p.stem) + ("" if dataset.mode == "image" else f"_{frame}")  # im.txt
            # æ‰“å°è¾“å‡ºï¼Œim.shape[2:]ä¸ºå›¾ç‰‡çš„å®½å’Œé«˜
            s += "%gx%g " % im.shape[2:]  # print string
            # å¾—åˆ°åŸå›¾çš„å®½å’Œé«˜
            # å½’ä¸€åŒ–å› å­ï¼Œç”¨äºå°†é¢„æµ‹æ¡†çš„åæ ‡ä»å½’ä¸€åŒ–åæ ‡è½¬æ¢ä¸ºåŸå§‹åæ ‡
            gn = torch.tensor(im0.shape)[[1, 0, 1, 0]]  # normalization gain whwh
            # ä¿å­˜æˆªå›¾ã€‚å¦‚æœsave_cropçš„å€¼ä¸ºtrueï¼Œåˆ™å°†æ£€æµ‹åˆ°çš„bounding_boxå•ç‹¬ä¿å­˜æˆä¸€å¼ å›¾ç‰‡ã€‚
            # å¦‚æœsave_cropä¸ºTrueï¼Œåˆ™å°†im0å¤åˆ¶ä¸€ä»½ï¼Œå¦åˆ™ä¸ºim0
            imc = im0.copy() if save_crop else im0  # for save_crop
            # åˆ›å»ºAnnotatorå¯¹è±¡ï¼Œç”¨äºåœ¨å›¾ç‰‡ä¸Šç»˜åˆ¶é¢„æµ‹æ¡†å’Œæ ‡ç­¾,im0ä¸ºè¾“å…¥å›¾ç‰‡ï¼Œline_widthä¸ºçº¿å®½ï¼Œexampleä¸ºæ ‡ç­¾
            # å¾—åˆ°ä¸€ä¸ªç»˜å›¾çš„ç±»ï¼Œç±»ä¸­é¢„å…ˆå­˜å‚¨äº†åŸå›¾ã€çº¿æ¡å®½åº¦ã€ç±»å
            annotator = Annotator(im0, line_width=line_thickness, example=str(names))

            # å¦‚æœé¢„æµ‹æ¡†çš„æ•°é‡å¤§äº0
            if len(det):
                # Rescale boxes from img_size to im0 size
                # å°†é¢„æµ‹æ¡†çš„åæ ‡ä»å½’ä¸€åŒ–åæ ‡è½¬æ¢ä¸ºåŸå§‹åæ ‡,im.shape[2:]ä¸ºå›¾ç‰‡çš„å®½å’Œé«˜ï¼Œdet[:, :4]ä¸ºé¢„æµ‹æ¡†çš„åæ ‡ï¼Œim0.shapeä¸ºå›¾ç‰‡çš„å®½å’Œé«˜
                # å°†é¢„æµ‹ä¿¡æ¯æ˜ å°„åˆ°åŸå›¾
                # å°†æ ‡æ³¨çš„bounding_boxå¤§å°è°ƒæ•´ä¸ºå’ŒåŸå›¾ä¸€è‡´ï¼ˆå› ä¸ºè®­ç»ƒæ—¶åŸå›¾ç»è¿‡äº†æ”¾ç¼©ï¼‰æ­¤æ—¶åæ ‡æ ¼å¼ä¸ºxyxy
                det[:, :4] = scale_boxes(im.shape[2:], det[:, :4], im0.shape).round()

                # Print results
                # æ‰“å°è¾“å‡º
                # éå†æ¯ä¸ªç±»åˆ«,unique()ç”¨äºè·å–æ£€æµ‹ç»“æœä¸­ä¸åŒç±»åˆ«æ˜¯æ•°é‡
                for c in det[:, 5].unique():
                    # nä¸ºæ¯ä¸ªç±»åˆ«çš„é¢„æµ‹æ¡†çš„æ•°é‡
                    n = (det[:, 5] == c).sum()  # detections per class
                    # sä¸ºæ¯ä¸ªç±»åˆ«çš„é¢„æµ‹æ¡†çš„æ•°é‡å’Œç±»åˆ«
                    s += f"{n} {names[int(c)]}{'s' * (n > 1)}, "  # add to string

                # Write results
                # å†™å…¥ç»“æœ
                # ä¿å­˜é¢„æµ‹ç»“æœï¼štxt/å›¾ç‰‡ç”»æ¡†/crop-image
                # éå†æ¯ä¸ªé¢„æµ‹æ¡†,xyxyä¸ºé¢„æµ‹æ¡†çš„åæ ‡ï¼Œconfä¸ºç½®ä¿¡åº¦ï¼Œclsä¸ºç±»åˆ«,reversed()å‡½æ•°ç”¨äºå°†åˆ—è¡¨åè½¬ï¼Œ*æ˜¯ä¸€ä¸ªæ‰©å±•è¯­æ³•ï¼Œ*xyxyè¡¨ç¤ºå°†xyxyä¸­çš„å…ƒç´ åˆ†åˆ«èµ‹å€¼ç»™x1,y1,x2,y2
                for *xyxy, conf, cls in reversed(det):
                    # ç±»åˆ«è½¬æ¢ä¸ºint
                    c = int(cls)  # integer class
                    # labelåç§°æ ¼å¼
                    label = names[c] if hide_conf else f"{names[c]}"
                    # ç½®ä¿¡åº¦ï¼Œå€¼ç±»å‹è½¬æ¢
                    confidence = float(conf)
                    # ç½®ä¿¡åº¦å­—ç¬¦ä¸²æ ¼å¼åŒ–
                    confidence_str = f"{confidence:.2f}"

                    if save_csv:
                        # save_csvï¼Œåˆ™å°†é¢„æµ‹æ¡†çš„åæ ‡å’Œç±»åˆ«å†™å…¥csvæ–‡ä»¶ä¸­
                        write_to_csv(p.name, label, confidence_str)

                    # å°†æ¯ä¸ªå›¾ç‰‡çš„é¢„æµ‹ä¿¡æ¯åˆ†åˆ«å­˜å…¥save_dir/labelsä¸‹çš„xxx.txtä¸­ æ¯è¡Œ: class_id + score + xywh
                    if save_txt:  # Write to file
                        # å¦‚æœsave_txtä¸ºTrueï¼Œåˆ™å°†é¢„æµ‹æ¡†çš„åæ ‡å’Œç±»åˆ«å†™å…¥txtæ–‡ä»¶ä¸­

                        # å°†é¢„æµ‹æ¡†çš„åæ ‡ä»åŸå§‹åæ ‡è½¬æ¢ä¸ºå½’ä¸€åŒ–åæ ‡(å¯æ ¹æ®å®é™…æƒ…å†µï¼Œæ˜¯å¦éœ€è¦åšå½’ä¸€åŒ–å¤„ç†ï¼Œå¦‚ï¼šéœ€è¦åŸå§‹åæ ‡æ—¶ï¼›å»æ‰"/gn"å³å¯)
                        # å°†xyxy(å·¦ä¸Šè§’+å³ä¸‹è§’)æ ¼å¼è½¬ä¸ºxywh(ä¸­å¿ƒç‚¹+å®½é•¿)æ ¼å¼ï¼Œå¹¶å½’ä¸€åŒ–ï¼Œè½¬åŒ–ä¸ºåˆ—è¡¨å†ä¿å­˜
                        xywh = (xyxy2xywh(torch.tensor(xyxy).view(1, 4)) / gn).view(-1).tolist()  # normalized xywh
                        # lineçš„å½¢å¼æ˜¯ï¼š â€ç±»åˆ« x y w hâ€œï¼Œè‹¥save_confä¸ºtrueï¼Œåˆ™lineçš„å½¢å¼æ˜¯ï¼šâ€ç±»åˆ« x y w h ç½®ä¿¡åº¦â€œ
                        # å¦‚æœsave_confä¸ºTrueï¼Œåˆ™å°†ç½®ä¿¡åº¦ä¹Ÿå†™å…¥txtæ–‡ä»¶ä¸­
                        line = (cls, *xywh, conf) if save_conf else (cls, *xywh)  # label format
                        # æ‰“å¼€txtæ–‡ä»¶,'a'è¡¨ç¤ºè¿½åŠ 
                        with open(f"{txt_path}.txt", "a") as f:
                            # å†™å…¥txtæ–‡ä»¶
                            # å†™å…¥å¯¹åº”çš„æ–‡ä»¶å¤¹é‡Œï¼Œè·¯å¾„é»˜è®¤ä¸ºâ€œruns\detect\exp*\labelsâ€
                            f.write(("%g " * len(line)).rstrip() % line + "\n")

                    # å¦‚æœsave_imgä¸ºTrueï¼Œåˆ™å°†é¢„æµ‹æ¡†å’Œæ ‡ç­¾ç»˜åˆ¶åœ¨å›¾ç‰‡ä¸Š
                    # åœ¨åŸå›¾ä¸Šç”»æ¡†+å°†é¢„æµ‹åˆ°çš„ç›®æ ‡å‰ªåˆ‡å‡ºæ¥ä¿å­˜æˆå›¾ç‰‡ï¼Œä¿å­˜åœ¨save_dir/cropsä¸‹ï¼Œåœ¨åŸå›¾åƒç”»å›¾æˆ–è€…ä¿å­˜ç»“æœ
                    if save_img or save_crop or view_img:  # Add bbox to image
                        # è·å–ç±»åˆ«
                        # ç±»åˆ«æ ‡å·
                        c = int(cls)  # integer class
                        # å¦‚æœhide_labelsä¸ºTrueï¼Œåˆ™ä¸æ˜¾ç¤ºæ ‡ç­¾ï¼Œå¦åˆ™æ˜¾ç¤ºæ ‡ç­¾ï¼Œå¦‚æœhide_confä¸ºTrueï¼Œåˆ™ä¸æ˜¾ç¤ºç½®ä¿¡åº¦ï¼Œå¦åˆ™æ˜¾ç¤ºç½®ä¿¡åº¦
                        # ç±»åˆ«å
                        label = None if hide_labels else (names[c] if hide_conf else f"{names[c]} {conf:.2f}")
                        # ç»˜åˆ¶é¢„æµ‹æ¡†å’Œæ ‡ç­¾
                        annotator.box_label(xyxy, label, color=colors(c, True))

                    # å¦‚æœsave_cropä¸ºTrueï¼Œåˆ™ä¿å­˜è£å‰ªçš„å›¾ç‰‡
                    # åœ¨åŸå›¾ä¸Šç”»æ¡†+å°†é¢„æµ‹åˆ°çš„ç›®æ ‡å‰ªåˆ‡å‡ºæ¥ä¿å­˜æˆå›¾ç‰‡ï¼Œä¿å­˜åœ¨save_dir/cropsä¸‹ï¼ˆå•ç‹¬ä¿å­˜ï¼‰
                    if save_crop:
                        # ä¿å­˜è£å‰ªçš„å›¾ç‰‡
                        save_one_box(xyxy, imc, file=save_dir / "crops" / names[c] / f"{p.stem}.jpg", BGR=True)

            # Stream results åœ¨å›¾ç‰‡ä¸Šç»˜åˆ¶é¢„æµ‹æ¡†å’Œæ ‡ç­¾å±•ç¤º
            # è·å–ç»˜åˆ¶é¢„æµ‹æ¡†å’Œæ ‡ç­¾çš„å›¾ç‰‡
            # å¦‚æœè®¾ç½®å±•ç¤ºï¼Œåˆ™showå›¾ç‰‡ / è§†é¢‘
            # im0æ˜¯ç»˜åˆ¶å¥½çš„å›¾ç‰‡
            im0 = annotator.result()
            # å¦‚æœview_imgä¸ºTrueï¼Œåˆ™å±•ç¤ºå›¾ç‰‡
            if view_img:
                # å¦‚æœç³»ç»Ÿä¸ºLinuxï¼Œä¸”pä¸åœ¨windowsä¸­
                if platform.system() == "Linux" and p not in windows:
                    # å°†pæ·»åŠ åˆ°windowsä¸­
                    windows.append(p)
                    # å…è®¸çª—å£è°ƒæ•´å¤§å°,WINDOW_NORMALè¡¨ç¤ºç”¨æˆ·å¯ä»¥è°ƒæ•´çª—å£å¤§å°ï¼ŒWINDOW_KEEPRATIOè¡¨ç¤ºçª—å£å¤§å°ä¸å˜
                    cv2.namedWindow(str(p), cv2.WINDOW_NORMAL | cv2.WINDOW_KEEPRATIO)  # allow window resize (Linux)
                    # è°ƒæ•´çª—å£å¤§å°ï¼Œä½¿å…¶ä¸å›¾ç‰‡å¤§å°ä¸€è‡´
                    cv2.resizeWindow(str(p), im0.shape[1], im0.shape[0])
                # æ˜¾ç¤ºå›¾ç‰‡
                cv2.imshow(str(p), im0)
                # ç­‰å¾…1æ¯«ç§’
                cv2.waitKey(1)  # 1 millisecond

            # Save results (image with detections)
            # å¦‚æœsave_imgä¸ºTrueï¼Œåˆ™ä¿å­˜å›¾ç‰‡
            # è®¾ç½®ä¿å­˜å›¾ç‰‡/è§†é¢‘
            if save_img:
                # å¦‚æœsave_imgä¸ºtrue,åˆ™ä¿å­˜ç»˜åˆ¶å®Œçš„å›¾ç‰‡

                # å¦‚æœæ•°æ®é›†æ¨¡å¼ä¸ºimage
                if dataset.mode == "image":
                    # ä¿å­˜å›¾ç‰‡
                    cv2.imwrite(save_path, im0)
                else:  # 'video' or 'stream'
                    # å¦‚æœæ˜¯è§†é¢‘æˆ–è€…"æµ"
                    # å¦‚æœæ•°æ®é›†æ¨¡å¼ä¸ºvideoæˆ–stream
                    # å¦‚æœvid_path[i]ä¸ç­‰äºsave_path
                    if vid_path[i] != save_path:  # new video
                        # vid_path[i] != save_path,è¯´æ˜è¿™å¼ å›¾ç‰‡å±äºä¸€æ®µæ–°çš„è§†é¢‘,éœ€è¦é‡æ–°åˆ›å»ºè§†é¢‘æ–‡ä»¶
                        # å°†save_pathèµ‹å€¼ç»™vid_path[i]
                        vid_path[i] = save_path
                        # ä»¥ä¸‹çš„éƒ¨åˆ†æ˜¯ä¿å­˜è§†é¢‘æ–‡ä»¶
                        # å¦‚æœvid_writer[i]æ˜¯cv2.VideoWriterç±»å‹
                        if isinstance(vid_writer[i], cv2.VideoWriter):
                            vid_writer[i].release()  # release previous video writer
                        if vid_cap:  # video
                            # è§†é¢‘
                            # è·å–è§†é¢‘çš„å¸§
                            fps = vid_cap.get(cv2.CAP_PROP_FPS)
                            # è·å–è§†é¢‘çš„å®½åº¦
                            w = int(vid_cap.get(cv2.CAP_PROP_FRAME_WIDTH))
                            # è·å–è§†é¢‘çš„é«˜åº¦
                            h = int(vid_cap.get(cv2.CAP_PROP_FRAME_HEIGHT))
                        else:  # stream
                            # è§†é¢‘æµ
                            # fpsï¼šå¸§æ•°ï¼Œwï¼šå®½åº¦ï¼Œhï¼šé«˜åº¦
                            fps, w, h = 30, im0.shape[1], im0.shape[0]
                        # è·å–æ–‡ä»¶ä¿å­˜è·¯å¾„
                        save_path = str(Path(save_path).with_suffix(".mp4"))  # force *.mp4 suffix on results videos
                        # è·å–è§†é¢‘å†™å…¥å¯¹è±¡
                        vid_writer[i] = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*"mp4v"), fps, (w, h))
                    # æ‰§è¡Œè§†é¢‘ä¿å­˜åˆ°æŒ‡å®šè·¯å¾„ä¸‹
                    vid_writer[i].write(im0)

        # Print time (inference-only)
        # æ‰“å°æ—¶é—´
        LOGGER.info(f"{s}{'' if len(det) else '(no detections), '}{dt[1].dt * 1E3:.1f}ms")

    '''================7.åœ¨ç»ˆç«¯é‡Œæ‰“å°å‡ºè¿è¡Œçš„ç»“æœ============================'''
    # Print results æ‰“å°ç»“æœ
    # æ¯å¼ å›¾ç‰‡çš„é€Ÿåº¦,å¹³å‡æ¯å¼ å›¾ç‰‡æ‰€è€—è´¹æ—¶é—´
    t = tuple(x.t / seen * 1e3 for x in dt)  # speeds per image
    LOGGER.info(f"Speed: %.1fms pre-process, %.1fms inference, %.1fms NMS per image at shape {(1, 3, *imgsz)}" % t)
    if save_txt or save_img:
        # å¦‚æœsave_txtä¸ºTrueï¼Œåˆ™æ‰“å°ä¿å­˜çš„æ ‡ç­¾æ•°é‡
        # æ ‡ç­¾ä¿å­˜çš„è·¯å¾„
        s = f"\n{len(list(save_dir.glob('labels/*.txt')))} labels saved to {save_dir / 'labels'}" if save_txt else ""
        # æ‰“å°ä¿å­˜çš„è·¯å¾„
        LOGGER.info(f"Results saved to {colorstr('bold', save_dir)}{s}")
    if update:
        # æ›´æ–°æ¨¡å‹
        """
        æ¨¡å‹è®­ç»ƒå®Œåï¼Œstrip_optimizerå‡½æ•°å°†optimizerä»ckptä¸­å»é™¤ï¼› å¹¶ä¸”å¯¹æ¨¡å‹è¿›è¡Œmodel.half(), å°†Float32çš„æ¨¡å‹->Float16ï¼Œ å¯ä»¥å‡å°‘æ¨¡å‹å¤§å°ï¼Œæé«˜inferenceé€Ÿåº¦
        """
        strip_optimizer(weights[0])  # update model (to fix SourceChangeWarning)


'''=================ä¸‰ã€Parse_opt()ç”¨æ¥è®¾ç½®è¾“å…¥å‚æ•°çš„å­å‡½æ•°==============================='''
def parse_opt():
    """
    åˆå§‹åŒ–è¿è¡Œå‚æ•°
    :return:
    """

    # åˆ›å»ºå‚æ•°è§£æå¯¹è±¡
    parser = argparse.ArgumentParser()
    # ä»¥ä¸‹é…ç½®æœ‰default-----------------------------
    # è®­ç»ƒçš„æƒé‡è·¯å¾„ï¼Œå¯ä»¥ä½¿ç”¨è‡ªå·±è®­ç»ƒçš„æƒé‡ï¼Œä¹Ÿå¯ä»¥ä½¿ç”¨å®˜ç½‘æä¾›çš„æƒé‡ã€‚é»˜è®¤å®˜ç½‘çš„æƒé‡
    parser.add_argument("--weights", nargs="+", type=str, default=ROOT / "yolov5s.pt", help="model path or triton URL")
    # source ä¹Ÿå¯ä»¥æ˜¯è§†é¢‘æ–‡ä»¶
    parser.add_argument("--source", type=str, default=ROOT / "data/images", help="file/dir/URL/glob/screen/0(webcam)")
    # é…ç½®æ•°æ®æ–‡ä»¶è·¯å¾„ï¼ŒåŒ…æ‹¬image/label/classesç­‰ä¿¡æ¯ï¼Œè®­ç»ƒè‡ªå·±çš„æ–‡ä»¶ï¼Œéœ€è¦ä½œç›¸åº”æ›´æ”¹ï¼Œå¯ä»¥ä¸ç”¨ç®¡
    parser.add_argument("--data", type=str, default=ROOT / "data/coco128.yaml", help="(optional) dataset.yaml path")
    # é¢„æµ‹æ—¶ç½‘ç»œè¾“å…¥å›¾ç‰‡çš„å°ºå¯¸ï¼Œé»˜è®¤å€¼ä¸º [640]
    parser.add_argument("--imgsz", "--img", "--img-size", nargs="+", type=int, default=[640], help="inference size h,w")
    # ç½®ä¿¡åº¦ï¼Œè¡¨ç¤ºç½®ä¿¡åº¦ä¸ºå¤šå°‘æ—¶(æ£€æµ‹è¿‡ç¨‹ä¸­ï¼Œä¼šåœ¨ç³»ç»ŸæŒ‡å®šçš„ç±»å‹é›†åˆä¸­ï¼Œè®¡ç®—å‡ºè¿™ä¸ªç›®æ ‡å¯¹åº”æ¯ä¸ªç±»å‹çš„ç½®ä¿¡åº¦å€¼)ï¼Œè®¤ä¸ºè¿™æ˜¯ä¸€ä¸ªç›®æ ‡å¯¹è±¡ï¼Œå°±ä¼šæ¡†å‡ºæ¥ï¼›æ˜¯ä¸€ä¸ªé˜ˆå€¼ï¼Œæ ¹æ®ä¸šåŠ¡éœ€æ±‚è®¾ç½®
    # ç®€å•ç†è§£ï¼Œç½®ä¿¡åº¦å¤§äºè¿™ä¸ªé˜ˆå€¼æ—¶ï¼Œå°±è®¤ä¸ºè¿™æ˜¯ä¸€ä¸ªç›®æ ‡å¯¹è±¡
    parser.add_argument("--conf-thres", type=float, default=0.25, help="confidence threshold")
    # iouç½®ä¿¡åº¦ï¼Œå®é™…æ£€æµ‹æ—¶ï¼Œä¸€ä¸ªç›®æ ‡ä¼šæœ‰è¢«å¤šä¸ªæ¡†æ¡†ä¸­ï¼Œè¿™æ—¶éœ€è¦é€‰ä¸­æœ€ä½³ä½ç½®çš„ä¸€ä¸ªæ¡†ã€‚NMS(éæå¤§å€¼æŠ‘åˆ¶)æœºåˆ¶å°±æ˜¯è§£å†³è¿™ä¸ªé—®é¢˜ï¼Œæ ¹æ®æ¡†ä¸æ¡†çš„IOU(ä¸¤ä¸ªæ¡†äº¤é›†é™¤ä»¥å¹¶é›†çš„å€¼)é‚£ä¸ªæœ€å¤§ï¼Œé€‰å‡ºæœ€åˆé€‚çš„æ¡†ã€‚
    # iou-threså°±æ˜¯é…ç½®è¿™ä¸ªé˜ˆå€¼çš„ï¼Œå…ˆæ ¹æ®IOUæ’åºï¼Œä»¥IOUæœ€å¤§çš„ä½œä¸ºåŸºç¡€å¯¹æ¯”æ¡†(IOUæœ€å¤§çš„ç•™ä¸‹çš„æ¦‚ç‡ä¹Ÿæœ€é«˜)ï¼ŒIOUå¤§äºå¤šå°‘æ—¶ï¼Œä¼šåˆå¹¶ä¸¤ä¸ªæ¡†(å»æ‰IOUä½çš„é‚£ä¸ªæ¡†)ï¼Œä¾æ¬¡æ‰§è¡Œï¼Œç›´è‡³éƒ½ä¸æ»¡è¶³é˜ˆå€¼ä¸ºæ­¢
    # åŸç†å‚è€ƒæœ¬æ–‡ä»¶çš„å¤‡æ³¨ä¿¡æ¯(37è¡Œå¤„)
    parser.add_argument("--iou-thres", type=float, default=0.45, help="NMS IoU threshold")
    # ä¿ç•™çš„æœ€å¤§æ£€æµ‹æ¡†æ•°é‡ï¼Œæ¯å¼ å›¾ç‰‡ä¸­æ£€æµ‹ç›®æ ‡çš„ä¸ªæ•°æœ€å¤šä¸º1000ç±»
    parser.add_argument("--max-det", type=int, default=1000, help="maximum detections per image")
    # æ‰§è¡Œçš„è®¾å¤‡é»˜è®¤ä¸ºç©ºï¼Œä¼šè‡ªåŠ¨æ£€æµ‹ã€‚
    parser.add_argument("--device", default="", help="cuda device, i.e. 0 or 0,1,2,3 or cpu")

    # ä»¥ä¸‹é…ç½®æ²¡æœ‰default(åªè¦é…ç½®è¿™ä¸ªå‚æ•°(å¯ä»¥ä¸å†™å€¼)ï¼Œè¿™ä¸ªå‚æ•°å°±æ˜¯true)-----------------------------
    # è®­ç»ƒå®Œæˆæ—¶ï¼Œæ˜¯å¦è‡ªåŠ¨æ˜¾ç¤ºç»“æœ
    parser.add_argument("--view-img", action="store_true", help="show results")
    # æ˜¯å¦æŠŠç»“æœã€‚ä¿å­˜ä¸ºtxtï¼ˆç»“æœexpæ–‡ä»¶å¤¹ï¼Œä¼šå¢åŠ ä¸€ä¸ªlabelsæ–‡ä»¶å¤¹ï¼Œä¿å­˜äº†ç›¸å…³å†…å®¹ï¼‰
    parser.add_argument("--save-txt", action="store_true", help="save results to *.txt")
    parser.add_argument("--save-csv", action="store_true", help="save results in CSV format")
    # æ˜¯å¦ä¿å­˜æ£€æµ‹ç»“æœçš„ç½®ä¿¡åº¦åˆ° txtæ–‡ä»¶ï¼Œé»˜è®¤ä¸º False
    parser.add_argument("--save-conf", action="store_true", help="save confidences in --save-txt labels")
    # æ˜¯å¦ä¿å­˜è£å‰ªé¢„æµ‹æ¡†å›¾ç‰‡ï¼Œé»˜è®¤ä¸ºFalseï¼Œä½¿ç”¨--save-crop åœ¨runs/detect/exp*/crop/å‰ªåˆ‡ç±»åˆ«æ–‡ä»¶å¤¹/ è·¯å¾„ä¸‹ä¼šä¿å­˜æ¯ä¸ªæ¥ä¸‹æ¥çš„ç›®æ ‡
    parser.add_argument("--save-crop", action="store_true", help="save cropped prediction boxes")
    # ä¸ä¿å­˜å›¾ç‰‡ã€è§†é¢‘ï¼Œè¦ä¿å­˜å›¾ç‰‡ï¼Œä¸è®¾ç½®--nosave åœ¨runs/detect/exp*/ä¼šå‡ºç°é¢„æµ‹çš„ç»“æœ
    parser.add_argument("--nosave", action="store_true", help="do not save images/videos")
    # é…ç½®ï¼Œç»“æœå›¾ç‰‡åªå±•ç¤ºé‚£äº›ç±»å‹çš„æ¡†ï¼Œå…¶ä½™çš„ä¸å±•ç¤º
    # nargs="+",è¡¨ç¤ºå¯ä»¥é…ç½®å¤šä¸ªå€¼
    # å¦‚ä¸‹é…ç½®åªå±•ç¤º"0 2 3"ä¸‰ä¸ªç±»å‹çš„æ¡†ï¼›æ ¹æ®éœ€æ±‚è®¾ç½®
    parser.add_argument("--classes", nargs="+", type=int, help="filter by class: --classes 0, or --classes 0 2 3")
    # nms å¢å¼º
    parser.add_argument("--agnostic-nms", action="store_true", help="class-agnostic NMS")
    # æ˜¯å¦ä½¿ç”¨æ•°æ®å¢å¼ºè¿›è¡Œæ¨ç†ï¼Œé»˜è®¤ä¸º False
    parser.add_argument("--augment", action="store_true", help="augmented inference")
    # bæ˜¯å¦å¯è§†åŒ–ç‰¹å¾å›¾ï¼Œé»˜è®¤ä¸º False
    parser.add_argument("--visualize", action="store_true", help="visualize features")
    # å‡å°‘æ¨¡å‹ä¸­çš„ä¸€äº›ç»„ä»¶
    parser.add_argument("--update", action="store_true", help="update all models")
    # ç»“æœé»˜è®¤ä¿å­˜çš„è·¯å¾„ï¼Œé»˜è®¤ä¸º'runs/detect'
    parser.add_argument("--project", default=ROOT / "runs/detect", help="save results to project/name")
    # ç»“æœé»˜è®¤ä¿å­˜çš„åç§°ï¼Œé»˜è®¤ä¸º'runs/detect'è·¯å¾„ä¸‹ï¼Œexp1ï¼Œexp2ï¼Œexp3â€¦â€¦
    parser.add_argument("--name", default="exp", help="save results to project/name")
    # æ¯æ¬¡çš„æ‰§è¡Œç»“æœï¼Œæ˜¯å¦éƒ½ä¿å­˜åœ¨ä¸€ä¸ªæ–‡ä»¶å¤¹é‡Œï¼Œ(é»˜è®¤æ¯æ¬¡éƒ½åˆ›å»ºæ–°çš„ç»“æœæ–‡ä»¶å¤¹ï¼šexp,exp1,exp2â€¦â€¦)
    parser.add_argument("--exist-ok", action="store_true", help="existing project/name ok, do not increment")
    # ç”» bounding box æ—¶çš„çº¿æ¡å®½åº¦ï¼Œé»˜è®¤ä¸º 3
    parser.add_argument("--line-thickness", default=3, type=int, help="bounding box thickness (pixels)")
    # æ˜¯å¦éšè—æ ‡ç­¾ä¿¡æ¯ï¼Œé»˜è®¤ä¸º False
    parser.add_argument("--hide-labels", default=False, action="store_true", help="hide labels")
    # æ˜¯å¦éšè—ç½®ä¿¡åº¦ä¿¡æ¯ï¼Œé»˜è®¤ä¸º False
    parser.add_argument("--hide-conf", default=False, action="store_true", help="hide confidences")
    # æ˜¯å¦ä½¿ç”¨ FP16 åŠç²¾åº¦è¿›è¡Œæ¨ç†ï¼Œé»˜è®¤ä¸º False
    parser.add_argument("--half", action="store_true", help="use FP16 half-precision inference")
    # æ˜¯å¦ä½¿ç”¨ OpenCV DNN è¿›è¡Œ ONNX æ¨ç†ï¼Œé»˜è®¤ä¸º False
    parser.add_argument("--dnn", action="store_true", help="use OpenCV DNN for ONNX inference")
    parser.add_argument("--vid-stride", type=int, default=1, help="video frame-rate stride")
    # è§£æå‘½ä»¤å‚æ•°ï¼Œå¹¶èµ‹å€¼ç»™opt;æ‰©å……ç»´åº¦
    opt = parser.parse_args()
    # å¦‚æœåªæœ‰ä¸€ä¸ªå‚æ•°ï¼Œåˆ™å°†å…¶æ‰©å±•ä¸ºä¸¤ä¸ªå‚æ•°ï¼Œå¯¹åº”å›¾ç‰‡çš„é«˜å’Œå®½
    opt.imgsz *= 2 if len(opt.imgsz) == 1 else 1  # expand
    # æ‰“å°å‚æ•°ï¼Œvars()å‡½æ•°è¿”å›å¯¹è±¡objectï¼Œçš„å±æ€§å’Œå±æ€§å€¼çš„å­—å…¸å¯¹è±¡
    print_args(vars(opt))
    # è¿”å›å‚æ•°
    return opt

'''=======================äºŒã€è®¾ç½®mainå‡½æ•°==================================='''
def main(opt):
    """
    ä¸»å‡½æ•°
    :param opt:
    :return:
    """

    # æ£€æŸ¥ç¯å¢ƒ/æ‰“å°å‚æ•°,ä¸»è¦æ˜¯requrement.txtçš„åŒ…æ˜¯å¦å®‰è£…ï¼Œç”¨å½©è‰²æ˜¾ç¤ºè®¾ç½®çš„å‚æ•°
    check_requirements(ROOT / "requirements.txt", exclude=("tensorboard", "thop"))
    # è¿è¡Œç¨‹åºï¼Œvars()å‡½æ•°è¿”å›å¯¹è±¡objectçš„å±æ€§å’Œå±æ€§å€¼å­—å…¸å¯¹è±¡
    run(**vars(opt))


# å‘½ä»¤ä½¿ç”¨
# python detect.py --weights best.pt --source  data/images/fishman.jpg # webcam
if __name__ == "__main__":
    opt = parse_opt() # è§£æå‚æ•°
    main(opt) # æ‰§è¡Œä¸»å‡½æ•°
